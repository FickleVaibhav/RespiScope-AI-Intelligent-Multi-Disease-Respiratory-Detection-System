# RespiScope-AI-Intelligent-Multi-Disease-Respiratory-Detection-System
RespiScope-AI is an advanced AI-powered diagnostic system that detects multiple respiratory diseases â€” such as asthma, bronchitis, pneumonia, COPD, and healthy lung conditions â€” using cough and breathing sounds captured through a smart digital stethoscope or built-in microphone.

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

A complete AI-powered respiratory disease detection system using cough and breathing sounds captured through a custom digital stethoscope. Detects **Asthma, Bronchitis, COPD, Pneumonia, and Healthy** conditions.

## ğŸ¯ Project Overview

RespiScope-AI combines hardware and software to create an affordable, accurate respiratory disease screening tool suitable for:
- Clinical screening and triage
- Remote patient monitoring
- Research and education
- Science fair and final-year projects

**Key Features:**
- ğŸ”¬ Multi-class classification (5 respiratory conditions)
- ğŸµ PANN-based audio feature extraction
- ğŸ§  CRNN/Transformer architecture for classification
- ğŸ”§ DIY digital stethoscope (no microcontroller needed)
- ğŸŒ Interactive web interface (Gradio & Streamlit)
- ğŸ“Š Comprehensive evaluation metrics
- ğŸ“š Multiple public dataset support

---

## ğŸ“ Repository Structure

```
RespiScope-AI/
â”œâ”€â”€ hardware/
â”‚   â”œâ”€â”€ stethoscope_assembly/
â”‚   â”‚   â”œâ”€â”€ assembly_steps.md
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ step1_components.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ step2_microphone.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ step3_wiring.jpg
â”‚   â”‚   â”‚   â””â”€â”€ final_assembly.jpg
â”‚   â”‚   â””â”€â”€ bill_of_materials.csv
â”‚   â”œâ”€â”€ microphone_connection/
â”‚   â”‚   â”œâ”€â”€ schematic_trrs.png
â”‚   â”‚   â”œâ”€â”€ schematic_usb.png
â”‚   â”‚   â””â”€â”€ wiring_guide.md
â”‚   â””â”€â”€ setup_guide.pdf
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ download_scripts/
â”‚   â”‚   â”œâ”€â”€ download_icbhi.py
â”‚   â”‚   â”œâ”€â”€ download_coswara.py
â”‚   â”‚   â””â”€â”€ download_all.sh
â”‚   â””â”€â”€ preprocessing/
â”‚       â”œâ”€â”€ audio_preprocessing.py
â”‚       â”œâ”€â”€ data_augmentation.py
â”‚       â””â”€â”€ prepare_splits.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pann_embeddings.py
â”‚   â”œâ”€â”€ crnn_classifier.py
â”‚   â”œâ”€â”€ transformer_classifier.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ checkpoints/
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ app_gradio.py
â”‚   â”œâ”€â”€ app_streamlit.py
â”‚   â”œâ”€â”€ static/
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â”œâ”€â”€ dataset_description.md
â”‚   â”œâ”€â”€ training_guide.md
â”‚   â””â”€â”€ project_report.pdf
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio_utils.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory_data_analysis.ipynb
â”‚   â””â”€â”€ model_comparison.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

## ğŸ”§ Hardware Assembly

### Components Required (Bill of Materials)

| Component | Specification | Quantity | Est. Cost (USD) |
|-----------|--------------|----------|-----------------|
| Analog Stethoscope | Standard dual-head | 1 | $15-30 |
| Electret Microphone | High-sensitivity (e.g., Adafruit 1713) | 1 | $7 |
| TRRS Audio Jack | 3.5mm 4-pole male | 1 | $2 |
| Heat Shrink Tubing | Various sizes | 1 set | $5 |
| Silicone Sealant | Waterproof | 1 tube | $5 |
| Wires | 22-24 AWG | 1m | $2 |
| USB Audio Adapter | (Optional) for better quality | 1 | $10-20 |

**Total Cost: ~$46-71**

### Assembly Instructions

See detailed step-by-step guide in `hardware/stethoscope_assembly/assembly_steps.md`

**Quick Overview:**
1. **Disassemble stethoscope chest piece** - Remove the diaphragm
2. **Mount microphone** - Secure inside chest piece facing diaphragm
3. **Solder connections** - Wire microphone to TRRS jack
4. **Seal and insulate** - Use heat shrink and silicone sealant
5. **Reassemble** - Put chest piece back together
6. **Test connection** - Verify audio input on PC/smartphone

### Connection Methods

**Option A: TRRS 3.5mm Jack** (Smartphone/PC compatible)
- Simple plug-and-play
- Works with most devices
- See `hardware/microphone_connection/schematic_trrs.png`

**Option B: USB Audio Interface** (Higher quality)
- Better signal-to-noise ratio
- Requires USB audio adapter
- See `hardware/microphone_connection/schematic_usb.png`

---

## ğŸ¤– AI Architecture

### Overview

```
Audio Input (16kHz) 
    â†“
Preprocessing (Normalization, Trimming)
    â†“
PANN Feature Extraction (PANNs CNN14)
    â†“
Embeddings (2048-dimensional)
    â†“
CRNN/Transformer Classifier
    â†“
Multi-class Output (5 classes)
    â†“
[Asthma | Bronchitis | COPD | Pneumonia | Healthy]
```

### Model Components

1. **PANN (Pretrained Audio Neural Networks)**
   - Pretrained on AudioSet (2M+ audio clips)
   - Extracts rich audio embeddings
   - CNN14 architecture (14-layer CNN)

2. **CRNN Classifier**
   - CNN layers for spatial features
   - Bi-directional LSTM for temporal modeling
   - Fully connected layers for classification
   - Dropout and batch normalization for regularization

3. **Transformer Classifier** (Alternative)
   - Multi-head self-attention
   - Positional encoding for temporal information
   - Better for long-range dependencies

### Performance Metrics

- **Accuracy**: Overall classification accuracy
- **F1-Score**: Per-class and weighted average
- **Confusion Matrix**: Class-wise performance
- **ROC-AUC**: One-vs-rest for each class
- **Precision/Recall**: Per-class metrics

---

## ğŸ“Š Datasets

### Supported Datasets

1. **ICBHI 2017 Respiratory Sound Database**
   - 920 audio recordings
   - 126 subjects
   - Crackles, wheezes, and normal sounds
   - Multiple respiratory conditions

2. **Coswara Dataset**
   - COVID-19 respiratory sounds
   - Cough, breathing, and voice samples
   - Crowdsourced global data

3. **Custom Dataset**
   - Add your own labeled recordings
   - Follow the preprocessing pipeline

### Dataset Statistics

See `docs/dataset_description.md` for detailed information.

---

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- CUDA-capable GPU (recommended for training)
- 8GB+ RAM
- 10GB+ free disk space

### Step 1: Clone Repository

```bash
git clone https://github.com/yourusername/RespiScope-AI.git
cd RespiScope-AI
```

### Step 2: Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Download Datasets

```bash
cd datasets/download_scripts
python download_icbhi.py
python download_coswara.py
cd ../..
```

### Step 5: Preprocess Data

```bash
cd datasets/preprocessing
python audio_preprocessing.py --input ../../data/raw --output ../../data/processed
python prepare_splits.py --data ../../data/processed --output ../../data/splits
cd ../..
```

---

## ğŸ“ Training

### Quick Start

```bash
python models/train.py \
    --data_path data/splits \
    --model_type crnn \
    --batch_size 32 \
    --epochs 100 \
    --lr 0.001 \
    --save_dir models/checkpoints
```

### Training Options

```bash
# Use CRNN model
python models/train.py --model_type crnn

# Use Transformer model
python models/train.py --model_type transformer

# Enable data augmentation
python models/train.py --augment

# Resume from checkpoint
python models/train.py --resume models/checkpoints/best_model.pth
```

### Monitor Training

Training logs and metrics are saved to `models/checkpoints/logs/`

Use TensorBoard for visualization:
```bash
tensorboard --logdir models/checkpoints/logs
```

---

## ğŸ”® Inference

### Command Line Inference

```bash
python models/inference.py \
    --audio_path path/to/audio.wav \
    --model_path models/checkpoints/best_model.pth \
    --model_type crnn
```

### Python API

```python
from models.inference import RespiScopeInference

# Initialize model
model = RespiScopeInference(
    model_path='models/checkpoints/best_model.pth',
    model_type='crnn'
)

# Predict single audio
result = model.predict('path/to/audio.wav')
print(f"Prediction: {result['class']}")
print(f"Confidence: {result['confidence']:.2%}")
print(f"All probabilities: {result['probabilities']}")
```

---

## ğŸŒ Web Interface

### Gradio Interface

```bash
cd webapp
python app_gradio.py
```

Access at: `http://localhost:7860`

**Features:**
- ğŸ™ï¸ Record audio directly from browser
- ğŸ“ Upload audio files (WAV, MP3, FLAC)
- ğŸ“Š Real-time predictions with confidence scores
- ğŸ“ˆ Probability distribution visualization
- ğŸ’¾ Download predictions as JSON

### Streamlit Interface

```bash
cd webapp
streamlit run app_streamlit.py
```

Access at: `http://localhost:8501`

**Features:**
- Similar to Gradio with alternative UI
- Batch processing support
- Historical predictions log

---

## ğŸ“ˆ Evaluation

### Generate Evaluation Report

```bash
python utils/metrics.py \
    --model_path models/checkpoints/best_model.pth \
    --test_data data/splits/test \
    --output_dir results/
```

**Outputs:**
- `confusion_matrix.png`
- `roc_curves.png`
- `classification_report.txt`
- `per_class_metrics.csv`

---

## ğŸ“– Documentation

### Architecture Details

See `docs/architecture_diagram.png` for visual representation.

### Dataset Information

Detailed dataset statistics and preprocessing steps in `docs/dataset_description.md`.

### Training Guide

Complete training pipeline explanation in `docs/training_guide.md`.

### Project Report

Comprehensive academic report in `docs/project_report.pdf`.

---

## ğŸ§ª Testing

Run unit tests:

```bash
pytest tests/
```

Run specific test:

```bash
pytest tests/test_preprocessing.py
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

**Software:** Apache License 2.0 - See [LICENSE](LICENSE) file for details.

**Hardware:** CERN Open Hardware Licence Version 2 - Permissive (CERN-OHL-P)

---

## ğŸ™ Acknowledgments

- **PANN**: Kong et al. "PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition"
- **ICBHI Dataset**: Rocha et al. "An open access database for the evaluation of respiratory sound classification algorithms"
- **Peter Ma's Digital Stethoscope**: Hardware design inspiration
- **AudioSet**: Google's large-scale audio dataset for pretraining

---

## ğŸ“§ Contact

**Project Maintainer**: Vaibhav Kumar Mohanty
- Email: mohantykvaibhav.email@example.com
- GitHub: [@FickleVaibhav](https://github.com/FickleVaibhav)

**Issues**: Please report bugs and feature requests on [GitHub Issues](https://github.com/FickleVaibhav/RespiScope-AI/issues)

---

## ğŸ¯ Citation

If you use this project in your research, please cite:

```bibtex
@software{respiscope_ai_2024,
  title={RespiScope-AI: Multi-Class Respiratory Disease Detection System},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/RespiScope-AI}
}
```

---

## ğŸ”® Future Enhancements

- [ ] Mobile app (Android/iOS)
- [ ] Edge deployment (Raspberry Pi, NVIDIA Jetson)
- [ ] Real-time continuous monitoring
- [ ] Multi-language support
- [ ] Cloud-based API
- [ ] Integration with EHR systems
- [ ] Explainable AI (Grad-CAM for audio)

---

## âš ï¸ Disclaimer

This system is intended for research and educational purposes only. It is **NOT** a medical device and should **NOT** be used for clinical diagnosis without proper validation and regulatory approval. Always consult qualified healthcare professionals for medical advice.

---

**Version**: 1.0.0  
**Last Updated**: 25 October 2025
**Status**: Active Development
